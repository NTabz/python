# this is the code I used to complete the 4th assignment for the python data structures coursera course
import pandas as pd
import numpy as np
with open('university_towns.txt') as file:
    list_uni = []
    for line in file:
        list_uni.append(line[:-1])
print(list_uni[:20])

data = []
state = []
region = []
for line in list_uni:
    if line[-6:] == '[edit]':
        state = line[:-6]
    elif line[-3] == '[':
        region = line[:-3]
    data.append([state, region])
print(data[:20])
uni = pd.DataFrame(data, columns = ['State','RegionName'])
##uni = uni.to_frame()
print(uni.head())
##### removes all unwanted characters within parentheses
uni['RegionName'] = uni['RegionName'].str.replace(r"\(.*\)", "")
uni = uni.dropna()
print(uni.head())
# reading excel file
gdp = pd.read_excel('gdplev.xls',skiprows=7)#skiprows=17,skip_footer=(38))
gdp = gdp[['Unnamed: 4', 'Unnamed: 5']]


gdp.columns = ['Quarter','GDP']
gdp['GDP'] = pd.to_numeric(gdp['GDP'])
ind = gdp.index[gdp['Quarter']=='2000q1']
print(ind)
gdp = gdp.loc[212:]
gdp = gdp.reset_index()
print(gdp.head())
quarters = []
for i in range(len(gdp) - 2):
    if (gdp.iloc[i][2] > gdp.iloc[i+1][2]) & (gdp.iloc[i+1][2] > gdp.iloc[i+2][2]):
        quarters.append(gdp.iloc[i][1])
print(quarters)
recession_end = []
for i in range(0,len(gdp)-4):
            if (gdp.iloc[i,2]) > (gdp.iloc[i+1,2]) and (gdp.iloc[i+1,2]) > (gdp.iloc[i+2,2]) and (gdp.iloc[i+2,2]) < (gdp.iloc[i+3,2]) and (gdp.iloc[i+3,2]) < (gdp.iloc[i+4,2]):
                recession_end = gdp.iloc[i+4,1]

print(recession_end)
recession_gdp = []
gdp_year = []
for i in range(0,len(gdp)-4):
            if (gdp.iloc[i,2]) > (gdp.iloc[i+1,2]) and (gdp.iloc[i+1,2]) > (gdp.iloc[i+2,2]) and (gdp.iloc[i+2,2]) < (gdp.iloc[i+3,2]) and (gdp.iloc[i+3,2]) < (gdp.iloc[i+4,2]):
                recession_gdp.append([gdp.iloc[i,2],gdp.iloc[i+1,2],gdp.iloc[i+2,2],gdp.iloc[i+3,2],gdp.iloc[i+4,2]])
                gdp_year.append([gdp.iloc[i,1],gdp.iloc[i+1,1],gdp.iloc[i+2,1],gdp.iloc[i+3,1],gdp.iloc[i+4,1]])
print(recession_gdp)
print(gdp_year)
house_df= pd.read_csv('City_Zhvi_AllHomes.csv')
#dropping unwanted columns
cols_drop = ['RegionID','Metro','CountyName','SizeRank']

house_df2 = house_df.drop(cols_drop,axis=1)
                       #house_df = house_df.drop(house_df['RegionID', 'Metro','CountyName','SizeRank'],axis = 1, inplace=True)
print(house_df2.head())
#changing state names in df2 to the dictionary data
states = {'OH': 'Ohio', 'KY': 'Kentucky', 'AS': 'American Samoa', 'NV': 'Nevada', 'WY': 'Wyoming', 
          'NA': 'National', 'AL': 'Alabama', 'MD': 'Maryland', 'AK': 'Alaska', 'UT': 'Utah', 'OR': 'Oregon', 
          'MT': 'Montana', 'IL': 'Illinois', 'TN': 'Tennessee', 'DC': 'District of Columbia', 'VT': 'Vermont', 
          'ID': 'Idaho', 'AR': 'Arkansas', 'ME': 'Maine', 'WA': 'Washington', 'HI': 'Hawaii', 'WI': 'Wisconsin', 
          'MI': 'Michigan', 'IN': 'Indiana', 'NJ': 'New Jersey', 'AZ': 'Arizona', 'GU': 'Guam', 'MS': 'Mississippi', 
          'PR': 'Puerto Rico', 'NC': 'North Carolina', 'TX': 'Texas', 'SD': 'South Dakota', 'MP': 'Northern Mariana Islands', 
          'IA': 'Iowa', 'MO': 'Missouri', 'CT': 'Connecticut', 'WV': 'West Virginia', 'SC': 'South Carolina', 'LA': 'Louisiana',
          'KS': 'Kansas', 'NY': 'New York', 'NE': 'Nebraska', 'OK': 'Oklahoma','FL': 'Florida', 'CA': 'California', 
          'CO': 'Colorado', 'PA': 'Pennsylvania', 'DE': 'Delaware', 'NM': 'New Mexico', 'RI': 'Rhode Island', 
          'MN': 'Minnesota', 'VI': 'Virgin Islands', 'NH': 'New Hampshire', 'MA': 'Massachusetts', 'GA': 'Georgia', 
          'ND': 'North Dakota', 'VA': 'Virginia'}
#now converting month data to quarterly means from only 2000 onwrafs
#check if apply/groupby can't be used here. no, because we're calculating average using values over several columns for every row
#changing states to states in dictionary above
house_df2['State'] = house_df2['State'].map(states)
house_df2.set_index(['State','RegionName'], inplace = True)
#print(house_df2.head())
#now dropping columns, and keeping only until 2000 to 2017
for col in house_df2.columns:
    if col[:2] == '19':
        house_df2.drop(col, axis=1, inplace = True)
#we are grouping three months at a time
qs = [list(house_df2.columns)[x:x+3] for x in range(0,len(house_df2.columns),3)]
print(qs)
#now we'll create new columns represnting quarters
#first let's create two lists
years = list(range(2000,2017))
quarter = ['q1','q2','q3','q4']
quar = []
for year in years:
    for q in quarter:
        quar.append((str(year)+q))

quar = quar[:67] #from starting to the 2nd last element
print(quar)
#adding all these new columns and the avg values
for col,q in zip(quar,qs):
    house_df2[col] = house_df2[q].mean(axis=1)
#cahnging the datafraem to only have these new columns
house_df2 = house_df2[quar]
#getting the data corr. to the recession quarters from the above datafram
    house_rec = house_df2.loc[:,'2008q3':'2009q2']
    #print(house_rec.head())
    house_rec2 = house_rec.copy()
    house_rec2['ratio'] = (house_rec['2008q3']-house_rec['2009q2'])/house_rec['2008q3']
    house_rec2 = house_rec2.reset_index()
    #print(house_rec2.head())
    #now we need to focus only on twons that are uni towns in the gdp dataframe
    uni_towns = pd.merge(uni,house_rec2,how= 'inner', left_on = ['State','RegionName'], right_on = ['State','RegionName']) 
    #print(uni_towns.head())
    #now getting townws that are NOT uni towns
    uni_not_head = list(uni_towns['RegionName']) #converting these non-uni town names into a list
    #dropping all rows containing the above regions from original house_rec2 dataframe
    house_rec2 = house_rec2[~house_rec2['RegionName'].isin([uni_not_head])]
    #print(house_rec2.head())
    #now we run the hypo test
    from scipy.stats import ttest_ind
    t,p = ttest_ind(uni_towns['ratio'].dropna(),house_rec2['ratio'].dropna())
    different = True if p<0.01 else False
    better = "university town" if uni_towns['ratio'].mean() < house_rec2['ratio'].mean() else "non-university town"
    print(p, different, better)
